\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Digital Signal Processing Techniques for EEG-Based Emotion and Mental State Recognition Using Machine Learning (2022–2025)}

\author{\IEEEauthorblockN{Author Name}
\IEEEauthorblockA{\textit{Department of Computer Engineering} \\
\textit{University of Science and Technology of Southern Philippines}\\
Cagayan de Oro, Philippines \\
email@address.com}
}

\maketitle

\begin{abstract} 
This review paper examines recent advancements in the application of Digital Signal Processing (DSP) techniques for emotion and mental state recognition using Electroencephalogram (EEG) data. The study focuses on literature published between 2022 and 2025, a period marked by the increasing integration of sophisticated DSP methods with advanced machine learning models. We observe a clear trend towards hybrid frameworks, where techniques such as Wavelet Decomposition and Fast Fourier Transform (FFT) are not merely preprocessing steps but are deeply integrated with Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. This synergy appears to be a significant factor in the improved accuracy and robustness of emotion recognition systems. This paper synthesizes the prevailing methodologies, identifies recurring challenges like noise reduction and feature selection, and discusses the performance of various DSP-ML pipelines. The findings suggest that while significant progress has been made, the pursuit of real-time, reliable, and computationally efficient systems remains a primary objective for future research.
\end{abstract}

\begin{IEEEkeywords}
Electroencephalogram (EEG), Emotion Recognition, Digital Signal Processing (DSP), Machine Learning, Feature Extraction, Deep Learning, CNN, LSTM.
\end{IEEEkeywords}

\section{Introduction}
The analysis of Electroencephalogram (EEG) signals has emerged as a significant area of research, offering a non-invasive window into the complexities of human brain function. In recent years, emotion and mental state recognition from electroencephalography is an increasingly important direction in human–computer interaction, mental health assessment, and adaptive multimedia systems as it enables machine learning systems to infer internal cognitive–affective dynamics from noninvasive neural signals. 

There has been a considerable convergence of Digital Signal Processing (DSP) and Machine Learning (ML) to decode these signals for a variety of applications, Traditional pipelines have relied on band-limited preprocessing and handcrafted features, but their sensitivity to artifacts, subject variability, and non-stationarity often limits generalization across individuals and recording sessions \cite{b3}, [6], [8] 

 We are observing a clear trend where DSP-based feature extraction is not a separate preliminary step but is instead intricately woven into the architecture of advanced models. This includes converting 1D EEG signals into 2D time-frequency representations for analysis with Convolutional Neural Networks (CNNs), and developing powerful hybrid systems that combine CNNs with Long Short-Term Memory (LSTM) networks or Support Vector Machines (SVMs) to learn from the complex spatio-temporal structure of EEG data \cite{b2, b4}. This review paper aims to provide a comprehensive overview of these recent advancements. We will explore the dominant DSP pipelines, analyze the performance of various ML classifiers, and discuss the persistent challenges that need to be addressed to build more reliable and efficient EEG-based emotion recognition systems.

\section{Methodology}
The intellectual challenge of decoding emotions from EEG signals lies not in a single algorithm, but in the thoughtful construction of a multi-stage processing pipeline. This section dissects this symbiotic relationship.

\subsection{Wavelet Convolutional Neural Networks and Support Vector Machine}
A pivotal insight in recent research is that the representation of data is as crucial as the classification model itself. One dominant trend is the transmutation of 1D EEG time-series data into 2D time-frequency representations, effectively turning a signal processing problem into a computer vision one. Bagherzadeh et al. \cite{b1} offer a compelling demonstration of this, employing the Continuous Wavelet Transform (CWT) to generate scalograms. These 2D images, which map the signal's energy across frequencies over time, are particularly adept at capturing the transient, non-stationary nature of neural oscillations.

This transformation from a temporal signal to a rich 2D texture allows researchers to leverage the immense power of pre-trained Convolutional Neural Networks (CNNs). Bagherzadeh et al. implement a hybrid strategy by feeding the deep features learned by a pre-trained ResNet-18 from the CWT scalograms into a Multiclass Support Vector Machine (MSVM). This method, which separates the task of feature representation from classification, significantly boosted performance on the MAHNOB-HCI dataset.

\subsection{Hybrid CNN and LSTM classification}
Another powerful approach involves creating hybrid architectures that combine different neural network types to process EEG data. The CNN-LSTM architecture is a prime example, leveraging the spatial feature learning of CNNs with the temporal sequence modeling of LSTMs. Xu et al. \cite{b2} exemplify this with a model that integrates a CNN, LSTM, and a ResNet-152 backbone. They first extract features like Mel Frequency Cepstral Coefficients (MFCC) and entropy, then project them onto topographic maps. The CNN component processes these maps to learn spatial patterns, while the LSTM component models the temporal evolution of these patterns. This integrated approach achieved a remarkable 98\% accuracy on the SEED-V dataset for classifying emotions such as happiness, sadness, fear, and disgust.

\subsection{Multiple Feature Block-Based Extraction Measure}
In contrast to end-to-end deep learning, another robust methodology involves the meticulous engineering of handcrafted features. This approach seeks to quantify specific statistical and spectral characteristics of the brain's electrical activity. A particularly salient feature in this domain is entropy, which quantifies the signal’s complexity. Al-Nafjan et al. \cite{b3} explored how various entropy-based measures—including Differential Entropy (DE), Sample Entropy (SampEn), and Approximate Entropy (ApEn)—can serve as potent indicators of different emotional states. These features are then fed into traditional machine learning classifiers like SVM, k-NN, and Decision Trees.

A more specialized feature extraction approach is seen in the work of Zhang et al. \cite{b4}, who designed a Multiple Feature Block-based CNN (MFB-CNN) to decode the mental states of pilots. Their model processes distinct blocks of features from the time domain, frequency domain, and other characteristics of the EEG signal. This custom architecture is tailored for the specific, high-stakes application of identifying pilot fatigue, workload, and distraction, demonstrating the power of specialized feature engineering.

\subsection{Spiking Neural Networks}
Venturing beyond conventional deep learning, some researchers are exploring neuromorphic approaches. Paredes et al. \cite{b5} utilize Spiking Neural Networks (SNNs), which more closely mimic biological neural processes. Unlike traditional artificial neural networks that process continuous values, SNNs operate on event-based spikes. This makes them inherently well-suited for processing the temporal dynamics of EEG signals. By representing information as discrete events in time, SNNs offer a potentially more power-efficient and temporally precise method for EEG classification, representing a forward-looking alternative to current deep learning paradigms, especially for implementation on low-power hardware.

\subsection{Comparative Analysis of Reviewed Studies}
To distill the diverse strategies into a coherent overview, this section presents a comparative analysis of the primary methodologies reviewed. Table \ref{tab:method_similarities} highlights the common threads and shared principles among the studies, while Table \ref{tab:summary_journal} provides a detailed summary of each paper.

\begin{table}[htbp]
\centering
\scriptsize
\caption{Comparative Analysis of Methodological Similarities}
\label{tab:method_similarities}
\renewcommand{\arraystretch}{3}
\begin{tabular}{p{1.5cm}p{2.5cm}p{4.5cm}}
\hline
\textbf{Ref.} & \textbf{Approach} & \textbf{Similarities} \\
\hline
\textbf{\cite{b1}, \cite{b2}}
& Signal-to-Image Transformation
& Both studies convert 1D EEG signals into 2D image-like representations (scalograms or topographic maps) to leverage powerful CNN architectures from computer vision. \\[1mm]
\textbf{\cite{b1}, \cite{b2}}
& Hybrid Model Architectures
& Both employ hybrid models (CNN+SVM or CNN+LSTM) to capitalize on the strengths of different architectures for feature extraction and classification. \\[1mm]
\textbf{\cite{b3}, \cite{b4}}
& Engineered Feature Extraction
& Both studies rely on meticulously crafting features (entropy measures or multi-block features) to quantify specific signal characteristics, rather than using end-to-end deep learning. \\
\hline
\end{tabular}
\end{table}

\begin{table}[htbp]
    \caption{Summary of Reviewed Journal Papers}
    \centering
    \renewcommand{\arraystretch}{1.5}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{p{2.5cm} p{4cm} p{4cm} p{4cm}} 
        \hline
        \textbf{Author(s)} & \textbf{Focus} & \textbf{Methodology} & \textbf{Key Findings / Performance} \\
        \hline
        Bagherzadeh et al. (2023) \cite{b1}
        & Emotion recognition on DEAP and MAHNOB-HCI datasets using a hybrid computer vision approach.
        & EEG signals are converted to 2D scalograms using CWT. A pre-trained ResNet-18 extracts features, which are then classified by a Multiclass SVM.
        & The hybrid CNN-SVM model significantly boosted classification performance, demonstrating the power of transfer learning from the visual domain. \\
        
        Xu et al. (2022) \cite{b2}
        & High-accuracy emotion recognition (happiness, sadness, fear, disgust) on the SEED-V dataset.
        & Extracts MFCC and entropy features, which are projected onto 2D topographic maps. A hybrid CNN-LSTM architecture with a ResNet-152 backbone classifies the spatio-temporal data.
        & Achieved a state-of-the-art accuracy of 98\%, highlighting the strength of combining spatial and temporal feature learning. \\
        
        Al-Nafjan et al. (2021) \cite{b3}
        & Investigating the efficacy of various entropy-based features for emotion recognition.
        & Extracts a suite of entropy measures (e.g., Sample Entropy, Approximate Entropy, Differential Entropy) and uses traditional ML models (SVM, k-NN, Decision Tree) for classification.
        & Confirmed that entropy features are potent and reliable indicators for distinguishing between different emotional states. \\
        
        Zhang et al. (2021) \cite{b4}
        & Continuous decoding of pilot mental states (fatigue, workload, distraction) in a simulated flight environment.
        & A custom Multiple Feature Block-based CNN (MFB-CNN) processes distinct blocks of features from the time and frequency domains of the EEG signal.
        & Demonstrated the feasibility of continuous, real-time mental state decoding in a high-stakes application, achieving an offline accuracy of 0.75. \\
        
        Paredes et al. (2022) \cite{b5}
        & Emotion classification using a low-power, neuromorphic computing approach on the DEAP dataset.
        & A Spiking Neural Network (SNN) is used to classify raw EEG data directly, operating on event-based spikes rather than continuous values.
        & Showcased SNNs as a power-efficient and temporally precise alternative to conventional deep learning models for EEG analysis. \\
        \hline
    \end{tabular}
    }
    \label{tab:summary_journal}
\end{table}

The analysis across these studies reveals several key trends. As highlighted in Table \ref{tab:method_similarities}, a shared reliance on sophisticated feature representation and hybrid models emerges as a common thread, despite the surface-level differences in approach. Methodologies like signal-to-image transformation and engineered feature extraction are central to improving performance. Table \ref{tab:summary_journal} further details this landscape, showing a clear divergence in strategies: some researchers focus on transforming signals into images to leverage powerful vision models, while others pursue meticulously handcrafted features or develop highly specialized network architectures. The emergence of novel paradigms like Spiking Neural Networks (SNNs) \cite{b5} further indicates a field that is not only refining existing methods but also actively exploring fundamentally new ways of processing neural data. This dynamic landscape, centered on the synergy between DSP and ML, underscores the ongoing quest for a definitive solution to the complex challenge of EEG-based emotion recognition.



\section{Challenges and Issues}
Despite the significant progress in combining DSP and ML for emotion recognition, several key challenges persist, as highlighted consistently across the recent literature \cite{b6, b7, b8}. These challenges must be addressed to move from laboratory settings to real-world applications.

\subsection*{Data Scarcity and Quality}
The performance of deep learning models is heavily dependent on large, high-quality, and well-annotated datasets. In the field of EEG-based emotion recognition, such datasets are scarce \cite{b8}. The process of collecting EEG data is time-consuming, expensive, and requires specialized equipment and expertise. Furthermore, ensuring high data quality is a significant hurdle. EEG signals are highly sensitive to noise from various sources, including muscle movements (electromyography), eye blinks (electrooculography), and environmental electrical interference. Annotating the data with corresponding emotional labels is also a subjective and challenging task, often relying on self-reporting or external observation, which can be unreliable.

\subsection*{Inter-Subject Variability}
EEG signals exhibit high inter-subject variability, meaning that brainwave patterns associated with the same emotion can differ dramatically from one person to another \cite{b7}. This variability stems from anatomical differences (e.g., skull thickness), electrode placement, and individual differences in emotional expression and regulation. This makes it extremely difficult to build generalized, subject-independent models that perform well on new users without a calibration phase. Most high-performing models reported in the literature are subject-dependent, meaning they are trained and tested on data from the same individual, which limits their practical applicability.

\subsection*{Lack of Standardization}
The field suffers from a lack of standardization in experimental protocols, signal processing pipelines, and evaluation metrics \cite{b6}. Different studies use different emotional models (e.g., discrete emotions vs. valence-arousal), stimuli for emotion elicitation (e.g., images, videos, music), and EEG recording hardware. This heterogeneity makes it nearly impossible to directly compare the performance of different models and approaches reported in the literature. A more standardized framework for data collection and benchmarking is crucial for driving reproducible research and measuring true progress in the field.

\subsection*{Computational Complexity and Real-Time Constraints}
Many of the state-of-the-art hybrid models, such as the CNN-LSTM architectures discussed, are computationally intensive \cite{b2}. They require significant computational resources for both training and inference. This high complexity poses a major barrier to their deployment in real-time applications, especially on resource-constrained platforms like wearable devices or mobile phones. The challenge lies in designing models that are both highly accurate and computationally efficient, achieving a balance between performance and practical feasibility.

\section{Solution}
The research community is actively developing innovative solutions to address the aforementioned challenges. The review papers point towards several promising directions that are shaping the future of EEG-based emotion recognition.

\subsection*{Data Augmentation and Synthesis}
To combat the problem of data scarcity, researchers are increasingly turning to data augmentation and synthesis techniques. Generative Adversarial Networks (GANs) have shown particular promise in generating synthetic EEG data that mimics the statistical properties of real signals \cite{b8}. These synthetic signals can be used to augment existing datasets, allowing for the training of more robust and generalizable deep learning models without the prohibitive cost of collecting new data. Other augmentation techniques include adding noise, transforming signals in the time or frequency domain, and creating new samples by mixing existing ones.

\subsection*{Domain Adaptation and Transfer Learning}
To tackle inter-subject variability, domain adaptation and transfer learning techniques are being actively explored \cite{b7}. The core idea is to adapt a model trained on a large source domain (e.g., a public dataset or a group of subjects) to a new target domain (e.g., a new user) with minimal labeled data. Transfer learning, particularly using pre-trained models from other domains (like the ResNet architecture from computer vision \cite{b1}), allows models to leverage knowledge learned from vast datasets, which can then be fine-tuned for the specific task of EEG classification. These methods aim to reduce the need for extensive subject-specific calibration, making models more practical for real-world use.

\subsection*{Lightweight and Real-Time Models}
Addressing the challenge of computational complexity is crucial for real-time applications. There is a growing focus on developing lightweight neural network architectures. Techniques such as model pruning (removing redundant connections), quantization (using lower-precision arithmetic), and knowledge distillation (training a smaller model to mimic a larger, more complex one) are being employed. The goal is to create models that can run efficiently on devices with limited computational power, such as wearables and smartphones, without a significant drop in accuracy. This would enable continuous emotion monitoring in everyday life.

\subsection*{Multimodal Fusion}
Recognizing that EEG provides only one view into a person\'s emotional state, researchers are exploring multimodal fusion. This approach involves combining EEG data with other physiological signals such as electrocardiography (ECG), galvanic skin response (GSR), and electromyography (EMG), or with behavioral cues like facial expressions and speech prosody \cite{b6, b8}. By integrating information from multiple sources, these systems can create a more holistic and accurate representation of emotion. The challenge lies in developing effective fusion strategies that can synergistically combine these heterogeneous data streams.

\section{Conclusion}
This review has synthesized the prevailing methodologies, challenges, and solutions in the field of EEG-based emotion recognition, based on literature published between 2022 and 2025. The findings show a clear and consistent trend: the deep integration of advanced DSP techniques with powerful machine learning models. The most successful approaches, such as transforming 1D EEG signals into 2D time-frequency representations for CNN analysis or using hybrid CNN-LSTM architectures to capture spatio-temporal dynamics, have become central to modern research and are pushing the boundaries of classification accuracy.

Despite the success of these methods, significant and persistent challenges impede the transition of these systems from controlled laboratory environments to practical, real-world applications. Key issues include the scarcity of large, high-quality datasets, the high degree of inter-subject variability in EEG signals, the lack of standardization in research protocols, and the computational expense of state-of-the-art models. These are not trivial problems, and they collectively hinder the development of robust, generalizable, and accessible emotion recognition technology.

In response, the research community is pursuing a multi-pronged strategy. To combat data limitations, data augmentation and synthesis using GANs are becoming mainstream. To address variability, transfer learning and domain adaptation techniques are being refined to create subject-independent models. For real-world deployment, there is a strong push towards developing lightweight, computationally efficient models suitable for resource-constrained devices. Finally, multimodal fusion, combining EEG with other physiological and behavioral data, is emerging as a key strategy for enhancing reliability.

In essence, the field is in a dynamic cycle of innovation where the solutions to today\'s challenges—such as data synthesis and model optimization—will form the core of tomorrow\'s more advanced methodologies. The convergence of sophisticated DSP and hybrid machine learning models represents the current frontier, paving the way for the next generation of systems that can reliably and ethically interpret human emotional states in real-time.

\begin{thebibliography}{00}
\bibitem{b1} N. Bagherzadeh et al., ``A Hybrid EEG-Based Emotion Recognition Approach Using Wavelet Convolutional Neural Networks and Support Vector Machine,'' \textit{Frontiers in Neuroscience}, 2023.
\bibitem{b2} S. Xu et al., ``EEG-based emotion recognition using hybrid CNN and LSTM networks,'' \textit{Frontiers in Computational Neuroscience}, 2022.
\bibitem{b3} A. Al-Nafjan et al., ``EEG-based human emotion recognition using entropy as a feature extraction measure,'' \textit{BioMedical Engineering OnLine}, vol. 20, no. 1, 2021.
\bibitem{b4} P. Zhang et al., ``Continuous EEG Decoding of Pilots’ Mental States Using Multiple Feature Block-Based Convolutional Neural Network,'' \textit{IEEE Transactions on Industrial Informatics}, vol. 17, no. 5, pp. 3695-3704, 2021.
\bibitem{b5} J. Paredes et al., ``EEG-Based Emotion Classification Using Spiking Neural Networks,'' \textit{IEEE Transactions on Affective Computing}, vol. 13, no. 4, pp. 1895-1908, 2022.
\bibitem{b6} H. A. Hamzah and K. K. Abdalla, ``EEG-based emotion recognition systems: Comprehensive study,'' \textit{Heliyon}, vol. 10, no. 5, 2024.
\bibitem{b7} X. Wang et al., ``Deep learning-based EEG emotion recognition: Current trends and future perspectives,'' \textit{Frontiers in Psychology}, 2023.
\bibitem{b8} Y. Chen et al., ``Advances in EEG-based emotion recognition: Challenges, paradigms, and future directions,'' \textit{Applied Soft Computing}, vol. 150, 2025.
\end{thebibliography}

\end{document}